import cv2
import dlib
import numpy as np
import time

import streamlit as st
from PIL import Image

# ---------------------------streamlit í™”ë©´ ì„¤ì •---------------------------
st.set_page_config(
    page_title="SOS ì‹ í˜¸ ê´€ë¦¬ í˜ì´ì§€",
    page_icon="ğŸš¨",
    layout="centered",
)

st.markdown("""
    <style>
    .fixed-header {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        background-color: #f0f2f6;
        padding: 10px 0;
        z-index: 100;
        border-bottom: 1px solid #ccc;
    }
    .title {
        font-size: 36px;
        color: #ff4b4b;
        text-align: center;
    }
    .subtitle {
        font-size: 24px;
        color: #333333;
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown('<div class="fixed-header">', unsafe_allow_html=True)
st.markdown('<div class="title">ğŸš¨ SOS ì‹ í˜¸ ê´€ë¦¬ í˜ì´ì§€ ğŸš¨</div>', unsafe_allow_html=True)
st.info(" ì´ í˜ì´ì§€ëŠ” ì‹¤ì‹œê°„ ì‹ í˜¸ ê°ì§€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ğŸ‘€")
st.markdown('</div>', unsafe_allow_html=True)

morse_code = []

# ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜
def reset_state():
    for key in st.session_state.keys():
        del st.session_state[key]
    st.experimental_rerun()

# ì‚¬ì´ë“œë°” ë²„íŠ¼ ì„¤ì •
if st.sidebar.button("ğŸ—‘ï¸ ìƒíƒœ ì´ˆê¸°í™”", key="reset_button"):
    reset_state()
if st.sidebar.button("âš ï¸ ê¸´ê¸‰ ë„ì›€ ìš”ì²­", key="emergency_button"):
    st.warning(" 112ì— ì—°ê²° ì¤‘ì…ë‹ˆë‹¤... ğŸ“")

# ---------------------------ì›¹ìº  ì‹¤í–‰---------------------------
cap = cv2.VideoCapture(0)
stframe = st.empty()

# NOTE: Haar Cascade Classifier(ì–¼êµ´ê³¼ ëˆˆ ê°ì§€)
# Source: https://github.com/opencv/opencv/tree/4.x/data/haarcascades
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

# NOTE: Dlib(ì–¼êµ´ ëœë“œë§ˆí¬ íƒì§€ ëª¨ë¸ ë¡œë“œ)
# Source: https://huggingface.co/spaces/asdasdasdasd/Face-forgery-detection/blob/ccfc24642e0210d4d885bc7b3dbc9a68ed948ad6/shape_predictor_68_face_landmarks.dat
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

# NOTE: EAR ì•Œê³ ë¦¬ì¦˜ ê³„ì‚° í•¨ìˆ˜
# Source: https://pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/)
def calculate_ear(eye):
    A = np.linalg.norm(eye[1] - eye[5])  # ëˆˆ ì•ìª½ ìˆ˜ì§ ê±°ë¦¬
    B = np.linalg.norm(eye[2] - eye[4])  # ëˆˆ ë’·ìª½ ìˆ˜ì§ ê±°ë¦¬
    C = np.linalg.norm(eye[0] - eye[3])  # ìˆ˜í‰ ê±°ë¦¬
    ear = (A + B) / (2.0 * C)
    return ear

# NOTE: This section of code for specifying landmark numbers is based on OpenCV resources
# ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ í•¨ìˆ˜
def get_eye_landmarks(landmarks, eye_points):
    return np.array([(landmarks.part(point).x, landmarks.part(point).y) for point in eye_points], dtype=np.float32)

THRESHOLD_EAR = 0.2  # EAR ì„ê³„ê°’ ì§€ì •

# ì´ˆê¸°ê°’ ì„¤ì •
blink_start_time = None  # ëˆˆ ê°ê¸° ì‹œì‘
blink_end_time = None    # ëˆˆ ê°ê¸° ì¢…ë£Œ

def check_sos_signal(morse_code):
    recent_patterns = ''.join(morse_code)
    
    # '_'ì™€ '.'ì˜ ê°œìˆ˜ë¥¼ ì„¸ê¸°
    count_dot = recent_patterns.count('.')
    count_underscore = recent_patterns.count('_')

    # SOS ì‹ í˜¸ì˜ ëŒ€ëµì ì¸ ë¹„ìœ¨ ì´ìƒì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©´ ì–´ë– í•œ ì‹ í˜¸ë¥¼ ë³´ë‚´ê³  ìˆë‹¤ê³  ê°€ì •í•¨
    if count_underscore >= 2 and count_dot >= 3:
        return True
    return False

SOS_DETECTED = False
SOS_SENT = False

cv2.namedWindow("Eyes", cv2.WINDOW_NORMAL)

# ì¼ì • ì‹œê°„ë™ì•ˆ ì–¼êµ´ ì •ë©´ì´ ë°”ë¼ë³´ê³  ìˆëŠ”ì§€ ê°ì§€
face_detected_start_time = None  # ì–¼êµ´ì´ ê°ì§€ëœ ì‹œì‘ ì‹œê°„
FACE_DETECTION_THRESHOLD = 5    # ì–¼êµ´ì„ ì •ë©´ìœ¼ë¡œ 5ì´ˆ ì´ìƒ ë°”ë¼ë´¤ì„ ë•Œ sos ì‹ í˜¸ë¡œ ì¸ì§€

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Haar Cascadeë¡œ ì–¼êµ´ ê°ì§€
    haar_faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # ì–¼êµ´ ê°ì§€ ì—¬ë¶€ í™•ì¸
    if len(haar_faces) > 0:
        if face_detected_start_time is None:
            face_detected_start_time = time.time() # ê°ì§€ë˜ë©´ ì‹œê°„ ì¸¡ì • ì‹œì‘
    else:
        face_detected_start_time = None
        SOS_DETECTED = False
        SOS_SENT = False
        morse_code.clear()

    if face_detected_start_time:
        elapsed_time = time.time() - face_detected_start_time
        if elapsed_time >= FACE_DETECTION_THRESHOLD:
            cv2.putText(frame, "Receive signals", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

            # 5ì´ˆ ì´ìƒ í™”ë©´ì„ ë°”ë¼ë´¤ìœ¼ë©´ ëˆˆ ê¹œë¹¡ì„ ê°ì§€
            faces = detector(gray)
            for face in faces:
                landmarks = predictor(gray, face)

                # NOTE: This section of code for specifying landmark numbers is based on OpenCV resources and PyImageSearch tutorials
                # ì™¼ìª½ ëˆˆê³¼ ì˜¤ë¥¸ìª½ ëˆˆì˜ ëœë“œë§ˆí¬ ê°€ì ¸ì˜¤ê¸°
                left_eye_points = list(range(36, 42))
                right_eye_points = list(range(42, 48))
                left_eye = get_eye_landmarks(landmarks, left_eye_points)
                right_eye = get_eye_landmarks(landmarks, right_eye_points)

                # ëˆˆ ì˜ì—­ ìë¥´ê¸°
                left_eye_center = np.mean(left_eye, axis=0).astype(int)
                right_eye_center = np.mean(right_eye, axis=0).astype(int)

                left_eye_img = frame[left_eye_center[1] - 20:left_eye_center[1] + 20, left_eye_center[0] - 20:left_eye_center[0] + 20]
                right_eye_img = frame[right_eye_center[1] - 20:right_eye_center[1] + 20, right_eye_center[0] - 20:right_eye_center[0] + 20]

                # NOTE: The code for calculating eye size using scale_factor is based on OpenCV resources
                #ìŠ¤ì¼€ì¼ 1.5ë°° í™•ëŒ€
                scale_factor = 1.5
                left_eye_scaled = (left_eye - left_eye_center) * scale_factor + left_eye_center
                right_eye_scaled = (right_eye - right_eye_center) * scale_factor + right_eye_center

                # í™•ëŒ€ëœ ëˆˆì„ ê¸°ì¤€ìœ¼ë¡œ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ í‘œì‹œí•˜ê¸°
                for i in range(36, 42):  # ì™¼ìª½ ëˆˆ
                    x_point = landmarks.part(i).x
                    y_point = landmarks.part(i).y
                    x_scaled = int((x_point - left_eye_center[0]) * scale_factor + left_eye_center[0])
                    y_scaled = int((y_point - left_eye_center[1]) * scale_factor + left_eye_center[1])
                    cv2.circle(frame, (x_scaled, y_scaled), 1, (0, 0, 255), -1)

                for i in range(42, 48):  # ì˜¤ë¥¸ìª½ ëˆˆ
                    x_point = landmarks.part(i).x
                    y_point = landmarks.part(i).y
                    x_scaled = int((x_point - right_eye_center[0]) * scale_factor + right_eye_center[0])
                    y_scaled = int((y_point - right_eye_center[1]) * scale_factor + right_eye_center[1])
                    cv2.circle(frame, (x_scaled, y_scaled), 1, (0, 0, 255), -1)

                # EAR ê³„ì‚°
                left_ear = calculate_ear(left_eye_scaled)
                right_ear = calculate_ear(right_eye_scaled)
                ear = (left_ear + right_ear) / 2.0

                # ë‘ ê°œì˜ ëˆˆ ì´ë¯¸ì§€ë¥¼ ê°€ë¡œë¡œ í•©ì¹˜ê¸°
                combined_eye_img = np.hstack((left_eye_img, right_eye_img))
                cv2.imshow("Eyes", combined_eye_img)
                
                cooldown_time = 0.2  # 200ms ë™ì•ˆì€ ì¤‘ë³µ ê°ì§€ ëª»í•˜ë„ë¡ ì„¤ì •
                last_blink_time = 0

                if time.time() - last_blink_time > cooldown_time:
                    if ear < THRESHOLD_EAR:
                        # ëˆˆ ê°ê¹€ ì‹œì‘ ì²˜ë¦¬
                        if blink_start_time is None:
                            blink_start_time = time.time()
                    else:
                        if blink_start_time is not None:
                            blink_end_time = time.time()
                            duration = blink_end_time - blink_start_time
                            blink_start_time = None
                            last_blink_time = time.time()

                            if duration <= 0.35:
                                morse_code.append('.')
                                print("Morse code:", ''.join(morse_code))
                            else:
                                morse_code.append('_')
                                print("Morse code:", ''.join(morse_code))

                            print(f"{time.strftime('%Y-%m-%d %H:%M:%S')}], Blink Duration: {duration:.2f}s, EAR: {ear:.2f}, morse_code: {' '.join(morse_code)}")

                # EAR ê°’ ë° íŒ¨í„´ í™”ë©´ í‘œì‹œ
                cv2.putText(frame, f"EAR: {ear:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                cv2.putText(frame, f"morse_code: {' '.join(morse_code)}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

    if ''.join(morse_code).count('_') >= 3:
        SOS_DETECTED = True

    if SOS_DETECTED:
        morse_string = ''.join(morse_code)

        # ì •í™•í•œ SOS ì‹ í˜¸ ê°ì§€
        if "...___..." in morse_string and not SOS_SENT:
            SOS_TIME = time.strftime('%Y-%m-%d %H:%M:%S')
            cv2.putText(frame, "SOS Detected!", (10, 150), cv2.FONT_HERSHEY_SIMPLEX,
                        2, (0, 0, 255), thickness=3)

            # Streamlitì—ì„œ SOS ì‹ í˜¸ ì¶œë ¥
            st.write(f"ê°ì§€ ì‹œê°„: {SOS_TIME}")
            st.write(f"ëª¨ìŠ¤ ë¶€í˜¸: {morse_string}")

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(frame_rgb)
            st.image(image, use_column_width=True)
            st.error("SOS signal!")

            # SOS ì‹ í˜¸ê°€ ê°ì§€ë˜ë©´ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸
            SOS_SENT = True
            morse_code.clear()

        # ìœ„í—˜ ì‹ í˜¸ ê°ì§€
        elif "...___" in morse_string and "...___..." not in morse_string and not SOS_SENT:
            SOS_TIME = time.strftime('%Y-%m-%d %H:%M:%S')
            cv2.putText(frame, "Warning signal!", (10, 150), cv2.FONT_HERSHEY_SIMPLEX,
                        1.5, (0, 140, 255), thickness=3)

            # Streamlitì—ì„œ ìœ„í—˜ ì‹ í˜¸ ì¶œë ¥
            st.write(f"ê°ì§€ ì‹œê°„: {SOS_TIME}")
            st.write(f"ëª¨ìŠ¤ ë¶€í˜¸: {morse_string}")

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(frame_rgb)
            st.image(image, use_column_width=True)
            st.success("Warning signal!")

            # ìœ„í—˜ ì‹ í˜¸ê°€ ê°ì§€ë˜ë©´ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸
            SOS_SENT = True

        # ìœ„í—˜ ì‹ í˜¸ ì´í›„ SOS ì‹ í˜¸ ê°ì§€ ì‹œ ìƒíƒœ ë¦¬ì…‹
        if "...___..." in morse_string and SOS_SENT:
            SOS_SENT = False

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):  # 'q' í‚¤ë¥¼ ëˆŒëŸ¬ ì´ˆê¸°í™”
            SOS_DETECTED = False
            SOS_SENT = False
            morse_code.clear()
            print("Reset")
            face_detected_start_time = None

    cv2.imshow("Frame", frame)

    # esc í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()    